{"pageProps":{"post":{"attributes":{},"html":"<p>We are going to pretend for a second that our initial page load is reeeeeally slow or expensive (it&#39;s neither at the moment) because it&#39;s querying the database with a heavy query. If that was true, we&#39;d want to cache our database response for that. Let&#39;s go do that.</p>\n<blockquote>\n<p>Premature optimization kills startups. Generally speaking, don&#39;t do cache something until it&#39;s proven to be a problem. Whenever you try to guess what the scaling problems are going to be, you&#39;re usually wrong, and now you have two problems: an unnecessary hack and an actual scaling problem.</p>\n</blockquote>\n<p>Let&#39;s first make a client that we can use anywhere. Make a <code>cache</code> directory in app and make an index.ts file and put this in there.</p>\n<pre><code class=\"hljs language-typescript\"><span class=\"hljs-keyword\">import</span> { <span class=\"hljs-title class_\">Redis</span> } <span class=\"hljs-keyword\">from</span> <span class=\"hljs-string\">&quot;@upstash/redis&quot;</span>;\n<span class=\"hljs-keyword\">const</span> redis = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-title class_\">Redis</span>({\n  <span class=\"hljs-attr\">url</span>: process.<span class=\"hljs-property\">env</span>.<span class=\"hljs-property\">UPSTASH_REDIS_REST_URL</span>,\n  <span class=\"hljs-attr\">token</span>: process.<span class=\"hljs-property\">env</span>.<span class=\"hljs-property\">UPSTASH_REDIS_REST_TOKEN</span>,\n});\n\n<span class=\"hljs-keyword\">export</span> <span class=\"hljs-keyword\">default</span> redis;\n</code></pre><p>From there in lib/data/articles.ts, add this</p>\n<pre><code class=\"hljs language-typescript\"><span class=\"hljs-comment\">// at top</span>\n<span class=\"hljs-keyword\">import</span> redis <span class=\"hljs-keyword\">from</span> <span class=\"hljs-string\">&quot;@/cache&quot;</span>;\n\n<span class=\"hljs-comment\">// top of getArticles</span>\n<span class=\"hljs-keyword\">const</span> cached = <span class=\"hljs-keyword\">await</span> redis.<span class=\"hljs-title function_\">get</span>(<span class=\"hljs-string\">&quot;articles:all&quot;</span>);\n<span class=\"hljs-keyword\">if</span> (cached) {\n  <span class=\"hljs-variable language_\">console</span>.<span class=\"hljs-title function_\">log</span>(<span class=\"hljs-string\">&quot;üéØ Get Articles Cache Hit!&quot;</span>);\n  <span class=\"hljs-keyword\">return</span> cached;\n}\n\n<span class=\"hljs-comment\">// above return statement</span>\n<span class=\"hljs-variable language_\">console</span>.<span class=\"hljs-title function_\">log</span>(<span class=\"hljs-string\">&quot;üôÖ‚Äç‚ôÇÔ∏è Get Articles Cache Miss!&quot;</span>);\nredis.<span class=\"hljs-title function_\">set</span>(<span class=\"hljs-string\">&quot;articles:all&quot;</span>, response, {\n  <span class=\"hljs-attr\">ex</span>: <span class=\"hljs-number\">60</span>, <span class=\"hljs-comment\">// one minute</span>\n});\n</code></pre><p>Now we cache the results of the getArticles call for one minute, meaning that we should really only see a little load on the database even under heavy traffic - most of those reads can just go straight to Redis and skip your database all together! Pretty cool!</p>\n<blockquote>\n<p>Could this be better? Definitely. Instead of just relying on the cache to expire and then reset it in code, we could set the cache to expire in 20 minutes, and then have the cache be refreshed every minute via a job. That way we guarantee that the database is going to be being called every minute with fresh data and no &quot;thundering herd&quot; problems. Thundering herd is what they call it when your cache expires and a ton of traffic spikes on your database all at once causing instability. But this will work for now and it&#39;s nice-and-simple.</p>\n</blockquote>\n<p>What if someone creates a new article? We want that to show instantly. So let&#39;s go clear the cache on article creation.</p>\n<pre><code class=\"hljs language-typescript\"><span class=\"hljs-comment\">// at top</span>\n<span class=\"hljs-keyword\">import</span> redis <span class=\"hljs-keyword\">from</span> <span class=\"hljs-string\">&quot;@/cache&quot;</span>;\n\n<span class=\"hljs-comment\">// bottom of createArticle, above return statement</span>\nredis.<span class=\"hljs-title function_\">del</span>(<span class=\"hljs-string\">&quot;articles:all&quot;</span>);\n</code></pre><p>That&#39;s it! We clear the cache on new article creation so it&#39;s always immediately available, but otherwise we assert that the data being a minute old is fresh enough.</p>\n","markdown":"We are going to pretend for a second that our initial page load is reeeeeally slow or expensive (it's neither at the moment) because it's querying the database with a heavy query. If that was true, we'd want to cache our database response for that. Let's go do that.\n\n> Premature optimization kills startups. Generally speaking, don't do cache something until it's proven to be a problem. Whenever you try to guess what the scaling problems are going to be, you're usually wrong, and now you have two problems: an unnecessary hack and an actual scaling problem.\n\nLet's first make a client that we can use anywhere. Make a `cache` directory in app and make an index.ts file and put this in there.\n\n```typescript\nimport { Redis } from \"@upstash/redis\";\nconst redis = new Redis({\n  url: process.env.UPSTASH_REDIS_REST_URL,\n  token: process.env.UPSTASH_REDIS_REST_TOKEN,\n});\n\nexport default redis;\n```\n\nFrom there in lib/data/articles.ts, add this\n\n```typescript\n// at top\nimport redis from \"@/cache\";\n\n// top of getArticles\nconst cached = await redis.get(\"articles:all\");\nif (cached) {\n  console.log(\"üéØ Get Articles Cache Hit!\");\n  return cached;\n}\n\n// above return statement\nconsole.log(\"üôÖ‚Äç‚ôÇÔ∏è Get Articles Cache Miss!\");\nredis.set(\"articles:all\", response, {\n  ex: 60, // one minute\n});\n```\n\nNow we cache the results of the getArticles call for one minute, meaning that we should really only see a little load on the database even under heavy traffic - most of those reads can just go straight to Redis and skip your database all together! Pretty cool!\n\n> Could this be better? Definitely. Instead of just relying on the cache to expire and then reset it in code, we could set the cache to expire in 20 minutes, and then have the cache be refreshed every minute via a job. That way we guarantee that the database is going to be being called every minute with fresh data and no \"thundering herd\" problems. Thundering herd is what they call it when your cache expires and a ton of traffic spikes on your database all at once causing instability. But this will work for now and it's nice-and-simple.\n\nWhat if someone creates a new article? We want that to show instantly. So let's go clear the cache on article creation.\n\n```typescript\n// at top\nimport redis from \"@/cache\";\n\n// bottom of createArticle, above return statement\nredis.del(\"articles:all\");\n```\n\nThat's it! We clear the cache on new article creation so it's always immediately available, but otherwise we assert that the data being a minute old is fresh enough.\n","slug":"caching","title":"Caching","section":"Key Value Store","icon":"key","filePath":"/home/runner/work/build-a-fullstack-nextjs-app-v4/build-a-fullstack-nextjs-app-v4/lessons/06-key-value-store/B-caching.md","nextSlug":"/lessons/key-value-store/counting","prevSlug":"/lessons/key-value-store/upstash"}},"__N_SSG":true}